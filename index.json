[{"authors":null,"categories":null,"content":"Dr. Andrey Kostenko is a Senior Data Scientist at IAG InsurTech Innovation Hub, also known as Firemark Labs, where he applies insights and cutting-edge techniques in computer vision, machine reading and advanced analytics on text, images and other forms of data towards new products and services that redefine insurance, as enabled by recent advances in machine learning, deep learning, reinforcement learning etc.\nBefore moving to Singapore in 2018, Andrey was a Data Scientist at trafficguard.ai, an Australian AdTech start-up developing novel data-driven algorithms for mobile ad fraud detection. In 2013, Andrey received his Doctorate Degree in Business Statistics and Econometrics from Monash University, Australia. By then, he had already had an MBA degree from the UK (thanks to the scholarship of the President of the Russian Federation to study overseas) and his first university degree from Russia.\nWhen not at work, Andrey is active on Kaggle, the best platform for testing various ideas and learning new skills in machine learning. In his leisure time, he enjoys travelling, solving puzzles, as well as reading on mathematicians and scientists.\n","date":-62135596800,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":-62135596800,"objectID":"598b63dd58b43bce02403646f240cd3c","permalink":"//localhost:1313/author/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/admin/","section":"author","summary":"Dr. Andrey Kostenko is a Senior Data Scientist at IAG InsurTech Innovation Hub, also known as Firemark Labs, where he applies insights and cutting-edge techniques in computer vision, machine reading and advanced analytics on text, images and other forms of data towards new products and services that redefine insurance, as enabled by recent advances in machine learning, deep learning, reinforcement learning etc.\nBefore moving to Singapore in 2018, Andrey was a Data Scientist at trafficguard.","tags":null,"title":"","type":"author"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":-62135596800,"objectID":"d41d8cd98f00b204e9800998ecf8427e","permalink":"//localhost:1313/author/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/","section":"author","summary":"","tags":null,"title":"Authors","type":"author"},{"authors":["Andrey Kostenko"],"categories":null,"content":"The Rmarkdown source code for the slides is available for download.\n","date":1558022400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1558022400,"objectID":"05374418d4f9990beae4c1e6f746a7b7","permalink":"//localhost:1313/talk/2ndaiconf/","publishdate":"2019-05-17T00:00:00+08:00","relpermalink":"/talk/2ndaiconf/","section":"talk","summary":"This talk reviews some the more useful resources on Machine Learning, Deep Learning and other subsets of Artificial Intelligence available to an R user today.","tags":["R","R packages","RStudio"],"title":"Implementing AI and Deep Learning in R, the well-known open-source platform for Data Science and Machine Learning","type":"talk"},{"authors":null,"categories":null,"content":"","date":1536422400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1536422400,"objectID":"6ef4e0031136e06be8b97ec35627419a","permalink":"//localhost:1313/tutorial/temp/","publishdate":"2018-09-09T00:00:00+08:00","relpermalink":"/tutorial/temp/","section":"tutorial","summary":"","tags":null,"title":"Coming soon","type":"docs"},{"authors":["Admin"],"categories":["time series"],"content":" Ex ante forecast is a forecast based solely on information available at the time of the forecast, whereas ex post forecast is a forecast that uses information beyond the time at which the forecast is made. Let’s discuss the two in more detail, as in different contexts the terms may mean slightly different things.\nIntroduction Only one thing is true about forecasts - they are always wrong. Any forecast $\\widehat{Y_t}$ of the actual value $Y_t$ is associated with the forecast error $e_t=Y_t−\\widehat{Y_t}$. The art and science of forecasting is all about bringing these forecast errors down to zero, as close as possible, for all future values of $t$. Doing this first for some of the past values of $t$ is often a useful exercise for developing a better forecasting model. It is this distinction between future and past values of $t$ that underlines the distinction between two types of forecast: ex post forecasts and ex ante forecasts.\nThe terms ex ante and ex post are among those few words in the forecasting literature that a general reader is unlikely to understand without first learning what they in fact mean. To see how the term ex ante have been used in the forecasting literature, check out the following excerpts:\n  Empirical results show that this procedure selects models that give reasonable ex ante forecast accuracy. The models allowing for serial correlation are shown to have the best ex ante forecasting performance. I looked primarily for studies that used real data to compare the ex ante forecasting accuracy of alternative methods. They examined the potential benefits of ex ante rules when contrasted with model selection based on within-sample model fitting. It is not clear to me from reading the paper if the resulting forecasts are true ex ante forecasts. The forecasts were tested on a holdout ex ante sample that was known only to the administrator of the competition. It may be, for example, that forecasters are using future information, perhaps inadvertently, so that forecasts are not ex ante, and I have known several cases where further study showed that a method was not as good as first suggested. The NN3 competition evaluates the ex ante accuracy of forecasting the next 18 observations on two homogeneous sets of 111 or 11 time series of varying length and time series patterns on multiple established error metrics. No matter how honest our efforts, and no matter how generous our colleagues, as long as comparisons were not genuinely ex ante a measure of doubt about our results was inevitable.   In general, ex ante is often used to mean ‘before-the-fact’ and ex post as ‘after-the-fact’. In the forecasting literature, an ex ante forecast is said to be any forecast that uses information available only at the time of the forecast. When a forecast prepared at certain time uses information available after that time, it is said to be an ex post forecast. A typical example of the latter is when known (actual rather than projected) values of external variables (regressors, predictors or drivers) are used in producing forecasts for the hold-out part of a time series. While ex post forecasts may be useful for exploring the properties of the forecasting model, it is ex ante forecasts (and the associated accuracy) that are ultimately important.\nForecasting univariate time series In the context of univariate time series forecasting, the difference between ex ante and ex post forecasts is well explained by Chan (2010). The remainder of this paragraph, including the quote below, follows him almost verbatim.\n The ex post forecasts are made when the “future” observations are known during the forecasting period. It is used as a means to check against known data so that the forecasting model can be evaluated. The ex ante forecasts are made beyond the present, when the future observations are not available for checking.\n Suppose that we observe $\\{Y_1,\\dots,Y_n\\}$, so we may use $\\{Y_1,\\dots,Y_t\\}$ for $t\u0026lt;n$ to estimate a model and use the estimated model to forecast $\\{Y_{t+1},\\dots,Y_n\\}$. These are ex post forecasts since we can use them to compare against the observed $\\{Y_{t+1},\\dots,Y_n\\}$.\nThe estimation period in this case is $t$. On the other hand, when we forecast $\\{Y_{n+1},\\dots,Y_{n+h}\\}$ for $h\u0026gt;0$, we are doing ex ante forecasts. After fitting a model, we estimate a future value $Y_{n+h}$ at time $n$ by $\\widehat{Y_n}(h)$ based on the fitted model, while the actual value of $Y_{n+h}$ is unknown.\nSomewhat differently from the above, in the context of univariate time series ex post forecast is sometimes used synonymously with the ‘model fit’ (i.e. small ex post forecast errors are associated with models that fit the data well). For example, according to Gardner \u0026amp; McKenzie (1988), in the 1960s and 1970s, the period of early theoretical development in quantitative forecasting, it was expected that\n The better the fit (ex post) of the forecasting model, the better the accuracy (ex ante) should be.\n Note that it is well known nowadays that the above statement is in general false. Ledolter (2010) also uses the term ex post when referring to the in-sample forecast performance:\n If sufficient observations are available, one should divide the series into two parts, derive estimates of the parameters that are necessary to construct the forecasts from the first part, and evaluate the accuracy of the ex ante forecasts from the observations in the holdout period. This is important, since models that fit the data well (i.e., have small ex post forecast errors) sometimes perform badly in forecasting, and vice versa.\n Forecasting with external variables In the context of time series with external variables ex post forecasts most commonly are forecast made with knowledge of the external variables. This type of forecast can be useful in quantifying the sources of forecast uncertainty, when answering questions like what part of a forecast error is due to a poor forecast of temperature and what part of it should be attributed to the forecasting model itself being imperfect. Quantifying the effect of errors due to the need to use estimated future values of external variables rather than their actual or observed values can often help improve the forecasting model. For example, Hyndman \u0026amp; Fan (2010) write:\n Specifically, ex ante forecasts are the forecasts made in advance using whatever information is available at the time. On the other hand, ex post forecasts are those that are made using information on the “driver variables” that is only known after the event being forecast. The difference between the ex ante forecasts and ex post forecasts will provide a measure of the effectiveness of the model for forecasting (taking out the effect of the forecast errors in the input variables).\n It is in this latter context that the distinction between the ex post and ex ante forecast is most useful. The reader of forecasting literature, however, should be aware that some well established names in the forecasting literature may use the terms simply to distinguish between the in-sample forecasts (done as part of the model fitting process) and the out-of-sample forecasts (done as part of the forecast evaluation process).\nReferences Chan, N. H. (2010). Time series applications to finance with R and S-Plus (2nd ed.). John Wiley \u0026amp; Sons. http://www.sta.cuhk.edu.hk/nhchan\nGardner, E. S., \u0026amp; McKenzie, E. (1988). Model identification in exponential smoothing. Journal of the Operational Research Society, 39(9), 863–867. http://doi.org/10.2307/2583529\nHyndman, R. J., \u0026amp; Fan, S. (2010). Density forecasting for long-term peak electricity demand. IEEE Transactions On Power Systems, 25(2), 1142–1153. http://doi.org/10.1109/TPWRS.2009.2036017\nLedolter, J. (2010). Prediction and forecasting. Encyclopedia of Statistical Sciences. http://doi.org/10.1002/0471667196.ess2046.pub3\n","date":1441468800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1441468800,"objectID":"7cb9b25c10a48cffabd134a389e23e9d","permalink":"//localhost:1313/post/ex-ante-vs-ex-post/","publishdate":"2015-09-06T00:00:00+08:00","relpermalink":"/post/ex-ante-vs-ex-post/","section":"post","summary":"Ex ante forecast is a forecast based solely on information available at the time of the forecast, whereas ex post forecast is a forecast that uses information beyond the time at which the forecast is made.","tags":["forecasting","terminology"],"title":"Time series forecasting: ex ante vs ex post","type":"post"},{"authors":["Admin"],"categories":["PhD"],"content":"This quick post is largely for testing purposes. It aims at sharing four motivational quotes that I carefully selected for the introductory page of the front matter of my PhD thesis. It was entitled Statistical issues in modelling and forecasting sequential count data and examined by professors James Taylor of Oxford University and Williams Dunsmuir of the University of New South Wales at the end of 2012. I will revisit some of the more interesting points developed there in this blog but for now, here are the promised quotes in the original order.\n\n It is not knowledge, but the act of learning, not possession but the act of getting there, which grants the greatest enjoyment. When I have clarified and exhausted a subject, then I turn away from it, in order to go into darkness again; the never-satisfied man is so strange if he has completed a structure, then it is not in order to dwell in it peacefully, but in order to begin another. I imagine the world conqueror must feel thus, who, after one kingdom is scarcely conquered, stretches out his arms for others. \u0026ndash; Carl Friedrich Gauss\n \n Every day you may make progress. Every step may be fruitful. Yet there will stretch out before you an ever-lengthening, ever-ascending, ever-improving path. You know you will never get to the end of the journey. But this, so far from discouraging, only adds to the joy and glory of the climb. \u0026ndash; Winston Churchill\n \n Finish each day and be done with it. You have done what you could. Some blunders and absurdities no doubt crept in, forget them as soon as you can. Tomorrow is a new day, you shall begin it well and serenely\u0026hellip; \u0026ndash; Ralph Waldo Emerson\n \n You can’t be perfect, but if you don’t try, you won’t be good enough. \u0026ndash; Paul Halmos\n \nWe all procrastinate from time to time, and my favourite way to do that while working on my thesis was to read much of what Paul Halmos wrote. The quickest way to learn what he wrote about, and how, is probably by reading this article by John Ewing.\n","date":1420128000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1420128000,"objectID":"ac3231395248d026bec87b43a08ef79a","permalink":"//localhost:1313/post/phd_motivational_quotes/","publishdate":"2015-01-02T00:00:00+08:00","relpermalink":"/post/phd_motivational_quotes/","section":"post","summary":"from Carl Gauss, Winston Churchill, Ralph Waldo Emerson and Paul Halmos","tags":["productivity","PhD thesis"],"title":"Four motivational quotes","type":"post"},{"authors":["Andrey V Kostenko","Rob J Hyndman"],"categories":null,"content":"","date":1225814400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1225814400,"objectID":"3123dce6ce258c8d81733dceb06b8564","permalink":"//localhost:1313/publication/sst2/","publishdate":"2008-11-05T00:00:00+08:00","relpermalink":"/publication/sst2/","section":"publication","summary":"Statistical significance testing has little useful purpose in business forecasting, and other tools are to be preferred. For selecting or ranking forecasting methods (especially those based on models) there exist simple but powerful and practical alternative approaches that are not tests. It is suggested that forecasters place less emphasis on p values and more emphasis on the predictive ability of models.","tags":["forecasting","statistical testing"],"title":"Forecasting without significance tests?","type":"publication"}]